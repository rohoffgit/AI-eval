{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud executed evaluations for continuous evaluation during development and production "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Evaluate your Generative AI application on the cloud with Azure AI Projects SDK (preview)<br>\n",
    "https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/cloud-evaluation\n",
    "\n",
    "Some hints from https://carlos.mendible.com/2025/02/27/custom-evaluators-with-ai-foundry/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cmd\n",
    "#pip install azure-identity azure-ai-projects azure-ai-ml azure-ai-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "PRIVATE = False\n",
    "DATA_DIR = Path(\"data\")\n",
    "TMP_DIR = Path(\"tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import override environment variables from .env file\n",
    "# or from private.env file if PRIVATE is True\n",
    "dotenv.load_dotenv('.env' if not PRIVATE else 'private.env', override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config dictionaries used by Azure AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Azure AI Foundry project\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP_AI\"),\n",
    "    \"project_name\": os.environ.get(\"AZURE_AI_PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "# Configuration for Azure OpenAI model\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    \"api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    \"type\": \"azure_openai\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://learn.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get AI Foundry project client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "# Create an Azure AI Client from a connection string. Available on Azure AI project Overview page.\n",
    "# https://learn.microsoft.com/en-us/python/api/azure-ai-projects/azure.ai.projects.aiprojectclient?view=azure-python-preview\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=credential,\n",
    "    conn_str=os.environ.get(\"AZURE_AI_PROJECT_CONNECTION_STRING\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded data asset id: /subscriptions/c11caebe-ea81-4036-9e58-ccf406d87ead/resourceGroups/sbn-ai-prod-swc/providers/Microsoft.MachineLearningServices/workspaces/10_stable/data/d76cbf36-3bac-49c3-8b1e-843bf4f44438/versions/1\n",
      "Uploaded data asset url: azureml://subscriptions/c11caebe-ea81-4036-9e58-ccf406d87ead/resourcegroups/sbn-ai-prod-swc/workspaces/10_stable/datastores/workspaceblobstore/paths/LocalUpload/d572131ff174c5ed77e2a11d4b1b945b/data.jsonl\n"
     ]
    }
   ],
   "source": [
    "# https://learn.microsoft.com/en-us/python/api/azure-ai-projects/azure.ai.projects.aiprojectclient?view=azure-python-preview#methods\n",
    "# Upload a file to the Azure AI Foundry project. This method required azure-ai-ml to be installed.\n",
    "# Return: tuple, containing asset id and asset URI of uploaded file.\n",
    "data_id, data_url = project_client.upload_file(DATA_DIR / \"data.jsonl\")\n",
    "print(f\"Uploaded data asset id: {data_id}\")\n",
    "print(f\"Uploaded data asset url: {data_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get built-in evaluator for their ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e.g. azureml://registries/azureml/models/F1Score-Evaluator/versions/3\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import F1ScoreEvaluator, GroundednessEvaluator, GroundednessProEvaluator, ViolenceEvaluator\n",
    "print(f'e.g. {F1ScoreEvaluator.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get custom evaluator library ids from Azure AI Foundry\n",
    "Note: this could also be looked up in the AI Foundry Portal (Evaluation Library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure AI Foundry project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Define ml_client to register custom evaluator\n",
    "# https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.mlclient?view=azure-python\n",
    "ml_client = MLClient(\n",
    "       subscription_id=os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "       resource_group_name=os.environ[\"AZURE_RESOURCE_GROUP_AI\"],\n",
    "       workspace_name=os.environ[\"AZURE_AI_PROJECT_NAME\"],\n",
    "       credential=credential\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper to built evaluator library id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "\n",
    "def get_evaluator_library_id(_evaluator: Model) -> str:\n",
    "    _ws = ml_client.workspaces.get(ml_client.workspace_name)\n",
    "    _id=f\"azureml://locations/{_ws.location}/workspaces/{_ws._workspace_id}/models/{_evaluator.name}/versions/{_evaluator.version}\"\n",
    "    print(f\"{_evaluator.name} library id: {_id}\")\n",
    "    return _id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get library ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Method evaluators: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnswerLenEvaluator library id: azureml://locations/swedencentral/workspaces/e7d65f7e-f370-4509-a296-c4d2c8befcad/models/AnswerLenEvaluator/versions/4\n"
     ]
    }
   ],
   "source": [
    "_evaluator = ml_client.evaluators.get(\"AnswerLenEvaluator\", label=\"latest\")\n",
    "answerLenEvaluator_libId = get_evaluator_library_id(_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FriendlinessEvaluator library id: azureml://locations/swedencentral/workspaces/e7d65f7e-f370-4509-a296-c4d2c8befcad/models/FriendlinessEvaluator/versions/6\n"
     ]
    }
   ],
   "source": [
    "_evaluator = ml_client.evaluators.get(\"FriendlinessEvaluator\", label=\"latest\")\n",
    "friendlinessEvaluator_libId = get_evaluator_library_id(_evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start evaluation in the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Created evaluation, evaluation ID:  60483791-47a0-4916-9c51-20624d7ed5ed\n",
      "Evaluation status:  Starting\n",
      "AI project URI:  https://ai.azure.com/build/evaluation/60483791-47a0-4916-9c51-20624d7ed5ed?wsid=/subscriptions/c11caebe-ea81-4036-9e58-ccf406d87ead/resourceGroups/sbn-ai-prod-swc/providers/Microsoft.MachineLearningServices/workspaces/10_stable\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# https://learn.microsoft.com/en-us/python/api/azure-ai-projects/azure.ai.projects.models.evaluation?view=azure-python-preview\n",
    "from azure.ai.projects.models import Evaluation\n",
    "\n",
    "# https://learn.microsoft.com/en-us/python/api/azure-ai-projects/azure.ai.projects.models.evaluatorconfiguration?view=azure-python-preview\n",
    "from azure.ai.projects.models import EvaluatorConfiguration\n",
    "\n",
    "# https://learn.microsoft.com/en-us/python/api/azure-ai-projects/azure.ai.projects.models.dataset?view=azure-python-preview\n",
    "from azure.ai.projects.models import Dataset\n",
    "\n",
    "# Create an evaluation\n",
    "evaluation = Evaluation(\n",
    "    display_name=\"Cloud evaluation\",\n",
    "    description=\"Evaluation of dataset\",\n",
    "    data=Dataset(id=data_id),\n",
    "    \n",
    "    # Note the evaluator configuration key must follow a naming convention\n",
    "    # the string must start with a letter with only alphanumeric characters \n",
    "    # and underscores. Take \"f1_score\" as example: \"f1score\" or \"f1_evaluator\" \n",
    "    # will also be acceptable, but \"f1-score-eval\" or \"1score\" will result in errors.\n",
    "    evaluators={\n",
    "        \"f1_score\": EvaluatorConfiguration(\n",
    "            id=F1ScoreEvaluator.id,\n",
    "        ),\n",
    "\n",
    "        \"groundedness\": EvaluatorConfiguration(\n",
    "            id=GroundednessEvaluator.id,\n",
    "            init_params={\n",
    "                \"model_config\": model_config\n",
    "            },\n",
    "        ),\n",
    "\n",
    "        \"groundedness_pro\": EvaluatorConfiguration(\n",
    "            id=GroundednessProEvaluator.id,\n",
    "            init_params={\n",
    "                \"azure_ai_project\": project_client.scope\n",
    "            },\n",
    "        ),\n",
    "\n",
    "        \"violence\": EvaluatorConfiguration(\n",
    "            id=ViolenceEvaluator.id,\n",
    "            init_params={\n",
    "                \"azure_ai_project\": project_client.scope\n",
    "            },\n",
    "        ),\n",
    "        \n",
    "        \"answer_length\": EvaluatorConfiguration(\n",
    "            id=answerLenEvaluator_libId,\n",
    "            data_mapping={\n",
    "                \"answer\": \"${data.response}\"\n",
    "            },\n",
    "        ),\n",
    "        \n",
    "        \"friendliness\": EvaluatorConfiguration(\n",
    "            id=friendlinessEvaluator_libId,\n",
    "            init_params={\n",
    "                \"model_config\": model_config\n",
    "            },\n",
    "            \n",
    "            data_mapping={\n",
    "            \"response\": \"${data.response}\"\n",
    "            } \n",
    "        )\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create evaluation\n",
    "evaluation_response = project_client.evaluations.create(\n",
    "    evaluation=evaluation,\n",
    ")\n",
    "\n",
    "# Get evaluation\n",
    "get_evaluation_response = project_client.evaluations.get(evaluation_response.id)\n",
    "\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Created evaluation, evaluation ID: \", get_evaluation_response.id)\n",
    "print(\"Evaluation status: \", get_evaluation_response.status)\n",
    "print(\"AI project URI: \", get_evaluation_response.properties[\"AiStudioEvaluationUri\"])\n",
    "print(\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureai_py3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
