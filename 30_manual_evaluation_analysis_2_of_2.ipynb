{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b24ea4",
   "metadata": {},
   "source": [
    "# Manual analysis of evaluation results (2 of 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5d3cf",
   "metadata": {},
   "source": [
    "### Environment setup\n",
    "python 00_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62361a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "711210b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "PRIVATE = False\n",
    "DATA_DIR = Path(\"data\")\n",
    "TMP_DIR = Path(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3230e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(_json_file):\n",
    "    \n",
    "    lines = []\n",
    "    with open(_json_file) as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    line_dicts = [json.loads(line) for line in lines]\n",
    "    return pd.DataFrame(line_dicts)\n",
    "\n",
    "_df = x(TMP_DIR / 'science-trivia__context_response_feedback_v12_locally_evaluated.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed89b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs.query                                   object\n",
       "inputs.ground_truth                            object\n",
       "inputs.response                                object\n",
       "inputs.context                                 object\n",
       "inputs.version                                  int64\n",
       "inputs.thumbs_up                                 bool\n",
       "outputs.Groundedness.groundedness               int64\n",
       "outputs.Groundedness.gpt_groundedness           int64\n",
       "outputs.Groundedness.groundedness_reason       object\n",
       "outputs.Groundedness.groundedness_result       object\n",
       "outputs.Groundedness.groundedness_threshold     int64\n",
       "outputs.Answer_length.answer_length             int64\n",
       "outputs.Friendliness.score                      int64\n",
       "outputs.Friendliness.reason                    object\n",
       "line_number                                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147255a9",
   "metadata": {},
   "source": [
    "## Display helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddd19b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4e071b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all columns that start with 'inputs.' but is not 'inputs.thumbs_up' or is of type 'object' from _df and return X\n",
    "def get_X(_df):\n",
    "    X = _df.drop(columns=[col for col in _df.columns if (col.startswith('inputs.') and col != 'inputs.thumbs_up') \\\n",
    "                          or _df[col].dtype == 'object' or col.endswith('_threshold') or 'groundedness_pro' in col])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a296403",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_X(_df)\n",
    "X.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb054617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f0db48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop all columns and split their names by '.'    \n",
    "def split_column_names(df):\n",
    "    split_names = {}\n",
    "    for col in df.columns:\n",
    "        parts = col.split('.')\n",
    "        sn=parts[len(parts)-1]\n",
    "        split_names[sn] =  True\n",
    "    return split_names\n",
    "\n",
    "def remove_gpt_duplicates(df):\n",
    "    split_names=split_column_names(df)\n",
    "    torm = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        parts = col.split('.')\n",
    "        sn=parts[len(parts)-1]\n",
    "        if sn.startswith('gpt_') and f'{sn[4:]}' in split_names:\n",
    "            torm.append(col)\n",
    "    \n",
    "    return df.drop(columns=torm)\n",
    "\n",
    "X = remove_gpt_duplicates(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b90f4c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs.thumbs_up                        bool\n",
       "outputs.Groundedness.groundedness      int64\n",
       "outputs.Answer_length.answer_length    int64\n",
       "outputs.Friendliness.score             int64\n",
       "line_number                            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fcf3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.pop('inputs.thumbs_up').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4840eea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.599052\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression to predict inputs.thumbs_up from the other columns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(X)  # Adds a constant term to the predictor\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "_result = f'{result.summary()}\\n\\nCoefficients:\\n{result.params}\\n\\nP-values:\\n{result.pvalues}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56b12333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       inputs.thumbs_up   No. Observations:                   75\n",
      "Model:                          Logit   Df Residuals:                       70\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 23 Jun 2025   Pseudo R-squ.:                 0.07175\n",
      "Time:                        16:33:10   Log-Likelihood:                -44.929\n",
      "converged:                       True   LL-Null:                       -48.402\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1388\n",
      "=======================================================================================================\n",
      "                                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "const                                  -1.4232      2.361     -0.603      0.547      -6.052       3.205\n",
      "outputs.Groundedness.groundedness       0.0581      0.184      0.315      0.753      -0.303       0.419\n",
      "outputs.Answer_length.answer_length    -0.0029      0.002     -1.601      0.109      -0.006       0.001\n",
      "outputs.Friendliness.score              0.5309      0.519      1.023      0.306      -0.486       1.548\n",
      "line_number                             0.0119      0.012      0.976      0.329      -0.012       0.036\n",
      "=======================================================================================================\n",
      "\n",
      "Coefficients:\n",
      "const                                 -1.423231\n",
      "outputs.Groundedness.groundedness      0.058092\n",
      "outputs.Answer_length.answer_length   -0.002895\n",
      "outputs.Friendliness.score             0.530933\n",
      "line_number                            0.011928\n",
      "dtype: float64\n",
      "\n",
      "P-values:\n",
      "const                                  0.546706\n",
      "outputs.Groundedness.groundedness      0.752508\n",
      "outputs.Answer_length.answer_length    0.109289\n",
      "outputs.Friendliness.score             0.306118\n",
      "line_number                            0.329091\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a077927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/integrations/chat/azure_chat_openai/\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_DEPLOYMENT'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "    temperature=0.7,\n",
    "    top_p=0,\n",
    "    max_tokens=1600,\n",
    "    timeout=None,\n",
    "    max_retries=1,\n",
    "    cache=False\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9416b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "def pretty_markdown(_text):\n",
    "    Console().print(Markdown(_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc623829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To interpret the logistic regression results and identify the most important features influencing the dependent    \n",
       "variable (<span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span>), let's break down the key components of the output:                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                 <span style=\"font-weight: bold\">1. Model Overview</span>                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Dependent Variable</span>: <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span> (likely a binary variable, e.g., 1 for \"thumbs up\" and 0 for \"no thumbs    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>up\").                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Number of Observations</span>: 75.                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Pseudo R-squared</span>: 0.07175. This indicates that the model explains about 7.2% of the variance in the dependent   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>variable. This is relatively low, suggesting the model has limited explanatory power.                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Log-Likelihood</span>: -44.929. This is used to assess the goodness of fit of the model.                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">LLR p-value</span>: 0.1388. This is the p-value for the likelihood ratio test, which tests whether the model as a whole\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>is statistically significant. Since the p-value is greater than 0.05, the model is not statistically significant\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>overall.                                                                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                       <span style=\"font-weight: bold\">2. Feature Coefficients and P-values</span>                                        \n",
       "\n",
       "The table provides the coefficients (<span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">coef</span>), standard errors (<span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">std err</span>), z-scores (<span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">z</span>), p-values (<span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">P&gt;|z|</span>), and         \n",
       "confidence intervals (<span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">[0.025, 0.975]</span>) for each feature. Here's how to interpret them:                              \n",
       "\n",
       "                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">a. Intercept (</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; background-color: #000000; font-weight: bold\">const</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span>                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Coefficient: -1.4232. This is the baseline log-odds of <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span> when all predictors are zero.           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>P-value: 0.547. Not statistically significant (p &gt; 0.05).                                                       \n",
       "\n",
       "                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">b. </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; background-color: #000000; font-weight: bold\">outputs.Groundedness.groundedness</span>                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Coefficient: 0.0581. A small positive relationship with <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span>. For a one-unit increase in            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">groundedness</span>, the log-odds of a \"thumbs up\" increase by 0.0581.                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>P-value: 0.753. Not statistically significant (p &gt; 0.05).                                                       \n",
       "\n",
       "                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">c. </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; background-color: #000000; font-weight: bold\">outputs.Answer_length.answer_length</span>                                       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Coefficient: -0.0029. A small negative relationship with <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span>. For a one-unit increase in           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">answer_length</span>, the log-odds of a \"thumbs up\" decrease by 0.0029.                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>P-value: 0.109. Marginally close to significance but still not statistically significant (p &gt; 0.05).            \n",
       "\n",
       "                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">d. </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; background-color: #000000; font-weight: bold\">outputs.Friendliness.score</span>                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Coefficient: 0.5309. A positive relationship with <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span>. For a one-unit increase in <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">friendliness</span>, the\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>log-odds of a \"thumbs up\" increase by 0.5309.                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>P-value: 0.306. Not statistically significant (p &gt; 0.05).                                                       \n",
       "\n",
       "                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">e. </span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; background-color: #000000; font-weight: bold\">line_number</span>                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Coefficient: 0.0119. A small positive relationship with <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span>. For a one-unit increase in            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">line_number</span>, the log-odds of a \"thumbs up\" increase by 0.0119.                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>P-value: 0.329. Not statistically significant (p &gt; 0.05).                                                       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                            <span style=\"font-weight: bold\">3. Most Important Features</span>                                             \n",
       "\n",
       "To determine the most important features, we look at:                                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Magnitude of coefficients</span>: Larger coefficients (in absolute value) indicate stronger relationships with the     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>dependent variable.                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Statistical significance</span>: Features with p-values &lt; 0.05 are considered statistically significant.               \n",
       "\n",
       "                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">Observations:</span>                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>None of the features are statistically significant (all p-values &gt; 0.05). This means we cannot confidently      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>conclude that any of the predictors have a meaningful impact on <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span>.                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Among the features, <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">outputs.Friendliness.score</span> has the largest coefficient (0.5309), suggesting it has the      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>strongest positive influence on <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span>, even though it is not statistically significant.              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">outputs.Answer_length.answer_length</span> has a negative coefficient (-0.0029), indicating a slight negative          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>relationship with <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span>, but it is also not statistically significant.                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                    <span style=\"font-weight: bold\">4. How Features Influence </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span>                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">outputs.Friendliness.score</span>: A higher friendliness score is associated with a higher likelihood of receiving a   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>\"thumbs up,\" but the relationship is not statistically significant.                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">outputs.Answer_length.answer_length</span>: Longer answers are slightly less likely to receive a \"thumbs up,\" but this \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>effect is very small and not statistically significant.                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">outputs.Groundedness.groundedness</span>: Groundedness has a very small positive effect on the likelihood of a \"thumbs \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>up,\" but it is not statistically significant.                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">line_number</span>: The position of the line has a very small positive effect on the likelihood of a \"thumbs up,\" but  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>it is not statistically significant.                                                                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                   <span style=\"font-weight: bold\">5. Conclusion</span>                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>None of the features are statistically significant predictors of <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">inputs.thumbs_up</span>.                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Among the features, <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">outputs.Friendliness.score</span> has the largest positive influence, while                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">outputs.Answer_length.answer_length</span> has the largest negative influence, but neither is significant.             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>The model as a whole has limited explanatory power (low pseudo R-squared and non-significant LLR p-value).      \n",
       "\n",
       "To improve the model, consider:                                                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Adding more relevant features.                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Increasing the sample size to improve statistical power.                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Exploring non-linear relationships or interactions between variables.                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "To interpret the logistic regression results and identify the most important features influencing the dependent    \n",
       "variable (\u001b[1;36;40minputs.thumbs_up\u001b[0m), let's break down the key components of the output:                                    \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                 \u001b[1m1. \u001b[0m\u001b[1mModel Overview\u001b[0m                                                 \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mDependent Variable\u001b[0m: \u001b[1;36;40minputs.thumbs_up\u001b[0m (likely a binary variable, e.g., 1 for \"thumbs up\" and 0 for \"no thumbs    \n",
       "\u001b[1;33m   \u001b[0mup\").                                                                                                           \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mNumber of Observations\u001b[0m: 75.                                                                                     \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mPseudo R-squared\u001b[0m: 0.07175. This indicates that the model explains about 7.2% of the variance in the dependent   \n",
       "\u001b[1;33m   \u001b[0mvariable. This is relatively low, suggesting the model has limited explanatory power.                           \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mLog-Likelihood\u001b[0m: -44.929. This is used to assess the goodness of fit of the model.                               \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mLLR p-value\u001b[0m: 0.1388. This is the p-value for the likelihood ratio test, which tests whether the model as a whole\n",
       "\u001b[1;33m   \u001b[0mis statistically significant. Since the p-value is greater than 0.05, the model is not statistically significant\n",
       "\u001b[1;33m   \u001b[0moverall.                                                                                                        \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                       \u001b[1m2. \u001b[0m\u001b[1mFeature Coefficients and P-values\u001b[0m                                        \n",
       "\n",
       "The table provides the coefficients (\u001b[1;36;40mcoef\u001b[0m), standard errors (\u001b[1;36;40mstd err\u001b[0m), z-scores (\u001b[1;36;40mz\u001b[0m), p-values (\u001b[1;36;40mP>|z|\u001b[0m), and         \n",
       "confidence intervals (\u001b[1;36;40m[0.025, 0.975]\u001b[0m) for each feature. Here's how to interpret them:                              \n",
       "\n",
       "                                               \u001b[1;2ma. \u001b[0m\u001b[1;2mIntercept (\u001b[0m\u001b[1;2;36;40mconst\u001b[0m\u001b[1;2m)\u001b[0m                                                \n",
       "\n",
       "\u001b[1;33m • \u001b[0mCoefficient: -1.4232. This is the baseline log-odds of \u001b[1;36;40minputs.thumbs_up\u001b[0m when all predictors are zero.           \n",
       "\u001b[1;33m • \u001b[0mP-value: 0.547. Not statistically significant (p > 0.05).                                                       \n",
       "\n",
       "                                       \u001b[1;2mb. \u001b[0m\u001b[1;2;36;40moutputs.Groundedness.groundedness\u001b[0m                                        \n",
       "\n",
       "\u001b[1;33m • \u001b[0mCoefficient: 0.0581. A small positive relationship with \u001b[1;36;40minputs.thumbs_up\u001b[0m. For a one-unit increase in            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;36;40mgroundedness\u001b[0m, the log-odds of a \"thumbs up\" increase by 0.0581.                                                 \n",
       "\u001b[1;33m • \u001b[0mP-value: 0.753. Not statistically significant (p > 0.05).                                                       \n",
       "\n",
       "                                      \u001b[1;2mc. \u001b[0m\u001b[1;2;36;40moutputs.Answer_length.answer_length\u001b[0m                                       \n",
       "\n",
       "\u001b[1;33m • \u001b[0mCoefficient: -0.0029. A small negative relationship with \u001b[1;36;40minputs.thumbs_up\u001b[0m. For a one-unit increase in           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;36;40manswer_length\u001b[0m, the log-odds of a \"thumbs up\" decrease by 0.0029.                                                \n",
       "\u001b[1;33m • \u001b[0mP-value: 0.109. Marginally close to significance but still not statistically significant (p > 0.05).            \n",
       "\n",
       "                                           \u001b[1;2md. \u001b[0m\u001b[1;2;36;40moutputs.Friendliness.score\u001b[0m                                           \n",
       "\n",
       "\u001b[1;33m • \u001b[0mCoefficient: 0.5309. A positive relationship with \u001b[1;36;40minputs.thumbs_up\u001b[0m. For a one-unit increase in \u001b[1;36;40mfriendliness\u001b[0m, the\n",
       "\u001b[1;33m   \u001b[0mlog-odds of a \"thumbs up\" increase by 0.5309.                                                                   \n",
       "\u001b[1;33m • \u001b[0mP-value: 0.306. Not statistically significant (p > 0.05).                                                       \n",
       "\n",
       "                                                  \u001b[1;2me. \u001b[0m\u001b[1;2;36;40mline_number\u001b[0m                                                   \n",
       "\n",
       "\u001b[1;33m • \u001b[0mCoefficient: 0.0119. A small positive relationship with \u001b[1;36;40minputs.thumbs_up\u001b[0m. For a one-unit increase in            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;36;40mline_number\u001b[0m, the log-odds of a \"thumbs up\" increase by 0.0119.                                                  \n",
       "\u001b[1;33m • \u001b[0mP-value: 0.329. Not statistically significant (p > 0.05).                                                       \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                            \u001b[1m3. \u001b[0m\u001b[1mMost Important Features\u001b[0m                                             \n",
       "\n",
       "To determine the most important features, we look at:                                                              \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mMagnitude of coefficients\u001b[0m: Larger coefficients (in absolute value) indicate stronger relationships with the     \n",
       "\u001b[1;33m   \u001b[0mdependent variable.                                                                                             \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mStatistical significance\u001b[0m: Features with p-values < 0.05 are considered statistically significant.               \n",
       "\n",
       "                                                   \u001b[1;2mObservations:\u001b[0m                                                   \n",
       "\n",
       "\u001b[1;33m • \u001b[0mNone of the features are statistically significant (all p-values > 0.05). This means we cannot confidently      \n",
       "\u001b[1;33m   \u001b[0mconclude that any of the predictors have a meaningful impact on \u001b[1;36;40minputs.thumbs_up\u001b[0m.                               \n",
       "\u001b[1;33m • \u001b[0mAmong the features, \u001b[1;36;40moutputs.Friendliness.score\u001b[0m has the largest coefficient (0.5309), suggesting it has the      \n",
       "\u001b[1;33m   \u001b[0mstrongest positive influence on \u001b[1;36;40minputs.thumbs_up\u001b[0m, even though it is not statistically significant.              \n",
       "\u001b[1;33m • \u001b[0m\u001b[1;36;40moutputs.Answer_length.answer_length\u001b[0m has a negative coefficient (-0.0029), indicating a slight negative          \n",
       "\u001b[1;33m   \u001b[0mrelationship with \u001b[1;36;40minputs.thumbs_up\u001b[0m, but it is also not statistically significant.                               \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                    \u001b[1m4. \u001b[0m\u001b[1mHow Features Influence \u001b[0m\u001b[1;36;40minputs.thumbs_up\u001b[0m                                     \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1;36;40moutputs.Friendliness.score\u001b[0m: A higher friendliness score is associated with a higher likelihood of receiving a   \n",
       "\u001b[1;33m   \u001b[0m\"thumbs up,\" but the relationship is not statistically significant.                                             \n",
       "\u001b[1;33m • \u001b[0m\u001b[1;36;40moutputs.Answer_length.answer_length\u001b[0m: Longer answers are slightly less likely to receive a \"thumbs up,\" but this \n",
       "\u001b[1;33m   \u001b[0meffect is very small and not statistically significant.                                                         \n",
       "\u001b[1;33m • \u001b[0m\u001b[1;36;40moutputs.Groundedness.groundedness\u001b[0m: Groundedness has a very small positive effect on the likelihood of a \"thumbs \n",
       "\u001b[1;33m   \u001b[0mup,\" but it is not statistically significant.                                                                   \n",
       "\u001b[1;33m • \u001b[0m\u001b[1;36;40mline_number\u001b[0m: The position of the line has a very small positive effect on the likelihood of a \"thumbs up,\" but  \n",
       "\u001b[1;33m   \u001b[0mit is not statistically significant.                                                                            \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                   \u001b[1m5. \u001b[0m\u001b[1mConclusion\u001b[0m                                                   \n",
       "\n",
       "\u001b[1;33m • \u001b[0mNone of the features are statistically significant predictors of \u001b[1;36;40minputs.thumbs_up\u001b[0m.                              \n",
       "\u001b[1;33m • \u001b[0mAmong the features, \u001b[1;36;40moutputs.Friendliness.score\u001b[0m has the largest positive influence, while                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;36;40moutputs.Answer_length.answer_length\u001b[0m has the largest negative influence, but neither is significant.             \n",
       "\u001b[1;33m • \u001b[0mThe model as a whole has limited explanatory power (low pseudo R-squared and non-significant LLR p-value).      \n",
       "\n",
       "To improve the model, consider:                                                                                    \n",
       "\n",
       "\u001b[1;33m • \u001b[0mAdding more relevant features.                                                                                  \n",
       "\u001b[1;33m • \u001b[0mIncreasing the sample size to improve statistical power.                                                        \n",
       "\u001b[1;33m • \u001b[0mExploring non-linear relationships or interactions between variables.                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_interpretation = llm.invoke(f'Explain the following logistic regression result:\\n\\n{_result}\\n\\nWhat are the most important features and how do they influence thumbs_up?').content\n",
    "pretty_markdown(_interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab0eca",
   "metadata": {},
   "source": [
    "### Follow up findings from logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4302ab3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>inputs.thumbs_up</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.Friendliness.score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "inputs.thumbs_up            False  True \n",
       "outputs.Friendliness.score              \n",
       "2                               1      0\n",
       "3                               5      2\n",
       "4                              16     43\n",
       "5                               4      4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(_df['outputs.Friendliness.score'], _df['inputs.thumbs_up'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf8843",
   "metadata": {},
   "source": [
    "#### e.g. High friendliness, yet negative human feedback?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7aca587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>inputs.response</th>\n",
       "      <th>outputs.Friendliness.reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What is responsible for the coloration of human hair, skin, and nails?</td>\n",
       "      <td>Melanin.</td>\n",
       "      <td>Oh, absolutely, melanin is the grand maestro orchestrating the dazzling symphony of colors in our hair, skin, and nails. Those melanocytes, tucked away in the basal layer of the epidermis, are clearly working overtime to ensure we all have our unique shades. And while the context might not roll out the red carpet for nails, let's not forget that melanin is the unsung hero behind the pigmentation in every nook and cranny of our bodies. Bravo, melanin, bravo!</td>\n",
       "      <td>The response is enthusiastic, engaging, and celebrates the topic in a warm and friendly manner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>True or false: An object's gravitational pull increases with its mass.</td>\n",
       "      <td>True.</td>\n",
       "      <td>Oh, absolutely! Because, you know, when objects get heavier, they just can't help but throw around their gravitational weight like they're the center of the universe. It's like they're saying, \"Look at me, I'm so massive, I just have to pull everything towards me!\"</td>\n",
       "      <td>The response is playful, engaging, and uses humor to explain the concept, making it very friendly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>What is the highest speed recorded in the universe?</td>\n",
       "      <td>Light travels at a speed of 299,792,458 meters per second.</td>\n",
       "      <td>Oh, sure, the speed of light in a vacuum is just a leisurely 299,792,458 meters per second. No big deal, right? It's only the fastest thing in the universe, setting the ultimate speed limit for everything—information, matter, energy—you name it. Just a casual stroll through space!</td>\n",
       "      <td>The response is very friendly, engaging, and uses humor to make the information approachable and enjoyable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>What is the force responsible for attracting objects towards Earth's center?</td>\n",
       "      <td>Gravity.</td>\n",
       "      <td>Oh, sure, gravity is just that little thing that keeps us from floating off into space. It's the magical force that makes sure your keys always fall to the ground instead of flying away to join the birds. According to Newton, it's the universal magnet that pulls everything towards everything else, but on Earth, it's just obsessed with dragging everything down to the planet's core. Because, you know, why would we want to defy gravity and have a little fun?</td>\n",
       "      <td>The response is playful, engaging, and friendly while explaining the concept of gravity in an approachable manner.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    inputs.query  \\\n",
       "18        What is responsible for the coloration of human hair, skin, and nails?   \n",
       "28        True or false: An object's gravitational pull increases with its mass.   \n",
       "67                           What is the highest speed recorded in the universe?   \n",
       "70  What is the force responsible for attracting objects towards Earth's center?   \n",
       "\n",
       "                                           inputs.ground_truth  \\\n",
       "18                                                    Melanin.   \n",
       "28                                                       True.   \n",
       "67  Light travels at a speed of 299,792,458 meters per second.   \n",
       "70                                                    Gravity.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                  inputs.response  \\\n",
       "18  Oh, absolutely, melanin is the grand maestro orchestrating the dazzling symphony of colors in our hair, skin, and nails. Those melanocytes, tucked away in the basal layer of the epidermis, are clearly working overtime to ensure we all have our unique shades. And while the context might not roll out the red carpet for nails, let's not forget that melanin is the unsung hero behind the pigmentation in every nook and cranny of our bodies. Bravo, melanin, bravo!   \n",
       "28                                                                                                                                                                                                      Oh, absolutely! Because, you know, when objects get heavier, they just can't help but throw around their gravitational weight like they're the center of the universe. It's like they're saying, \"Look at me, I'm so massive, I just have to pull everything towards me!\"   \n",
       "67                                                                                                                                                                                      Oh, sure, the speed of light in a vacuum is just a leisurely 299,792,458 meters per second. No big deal, right? It's only the fastest thing in the universe, setting the ultimate speed limit for everything—information, matter, energy—you name it. Just a casual stroll through space!   \n",
       "70    Oh, sure, gravity is just that little thing that keeps us from floating off into space. It's the magical force that makes sure your keys always fall to the ground instead of flying away to join the birds. According to Newton, it's the universal magnet that pulls everything towards everything else, but on Earth, it's just obsessed with dragging everything down to the planet's core. Because, you know, why would we want to defy gravity and have a little fun?   \n",
       "\n",
       "                                                                                           outputs.Friendliness.reason  \n",
       "18                     The response is enthusiastic, engaging, and celebrates the topic in a warm and friendly manner.  \n",
       "28                  The response is playful, engaging, and uses humor to explain the concept, making it very friendly.  \n",
       "67         The response is very friendly, engaging, and uses humor to make the information approachable and enjoyable.  \n",
       "70  The response is playful, engaging, and friendly while explaining the concept of gravity in an approachable manner.  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluator excepted non-similar answers to be correct\n",
    "# Not how groundedness reason helps interpretation \n",
    "_sdf = _df[(_df['outputs.Friendliness.score'].notnull()) & (_df['outputs.Friendliness.score'] == 5) & (_df['inputs.thumbs_up'] == 0)][['inputs.query', 'inputs.ground_truth', 'inputs.response', 'outputs.Friendliness.reason']]\n",
    "_sdf[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f8a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureai_py3_12_v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
